\documentclass[11pt]{article}
\pagestyle{plain}
%\documentclass{article}
%\usepackage[utf8]{inputenc}
%\usepackage[english]{babel}

\usepackage{latexsym,amsmath,amssymb}
\usepackage{amsthm}
%\usepackage[notref,notcite]{showkeys}
\usepackage{amsfonts}
\usepackage{geometry}
\usepackage{graphicx}
\usepackage{lmodern}
\usepackage{pifont}
\usepackage{tikz}
\usepackage{pgfplots}
\usepackage{thmtools}
\usepackage{wrapfig}
\usepackage{extarrows}
\usepackage{breqn}
\usepackage{physics}
\usepackage{afterpage}
\usepackage{enumitem}
\usepackage[utf8]{inputenc}
\usepackage{mathrsfs}
\usepackage{scalerel}
\usepackage{stackengine,wasysym}
\usepackage{aligned-overset}
\usepackage{stackengine}
\usepackage{mathtools}
\usepackage{nccmath}
\usepackage{url}
\graphicspath{ {images/} }

\usepackage{hyperref}
\hypersetup{
    colorlinks = true,
    linkcolor = blue,
    filecolor = magenta,      
    urlcolor = blue,
    citecolor = blue,
}

\urlstyle{same}


\setlength{\oddsidemargin}{1pt}
\setlength{\evensidemargin}{1pt}
\setlength{\marginparwidth}{30pt} % these gain 53pt width
\setlength{\topmargin}{1pt}       % gains 26pt height
\setlength{\headheight}{1pt}      % gains 11pt height
\setlength{\headsep}{1pt}         % gains 24pt height
%\setlength{\footheight}{12 pt} 	  % cannot be changed as number must fit
\setlength{\footskip}{24pt}       % gains 6pt height
\setlength{\textheight}{650pt}    % 528 + 26 + 11 + 24 + 6 + 55 for luck
\setlength{\textwidth}{460pt}     % 360 + 53 + 47 for luck

\title{Sections and Chapters}

\newtheorem{definition}{Definition}[section]
\newtheorem{theorem}{Theorem}[section]
\newtheorem{corollary}{Corollary}[theorem]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}{Proposition}[section]
\newtheorem{exercise}{Exercise}[section]
\newtheorem{remark}{Remark}[section]
\theoremstyle{definition}
\newtheorem{example}{Example}[section]
\numberwithin{equation}{subsection}

\makeatletter
\newenvironment{intheorem}[1][]
  {%
   \refstepcounter{theorem}%
   {\the\thm@headfont Theorem \thetheorem\@ifempty{#1}{}{ (#1)}.}%
   \the\thm@bodyfont
  }%
  {\par}
\makeatother

\def\dsp{\def\baselinestretch{1.35}\large
\normalsize}
%%%%This makes a double spacing. Use this with 11pt style. If you
%%%%want to use this just insert \dsp after the \begin{document}
%%%%The correct baselinestretch for double spacing is 1.37. However
%%%%you can use different parameter.


\def\U{{\mathcal U}}

\begin{document}

\centerline{\Large \bf Analysis Qualifying Exam}
\centerline{Zhen Yao}

\tableofcontents{}


\bigskip


\newpage


\section{May 2019 Exam}

\begin{exercise}
Let $\sigma > 0$. Let $\left\{f_k\right\}_{k\in \mathbb{N}}$ be a sequence of functions $f_k: \mathbb{R} \to \mathbb{R}$ with $f_k(0) = 0$. Moreover, let $\left\{A_k\right\}_{k\in \mathbb{N}} \subset [0,\infty)$ be a {\it bounded} sequence of real numbers such that 
\begin{align*}
    \left|f_k(x) - f_k(y)\right| \leq A_k |x - y|^\sigma \,\, \text{for all} \,\, x, y\in \mathbb{R}.
\end{align*}
\begin{enumerate}[label=(\alph*)]
    \item Show that there exists $f: \mathbb{R}\to \mathbb{R}$ such that a subsequence $f_{k_i}$ converges uniformly to $f$ in every interval $[-a,a], a > 0$.
    
    \item {\rm *} Show that $f$ satisfies 
    \begin{align*}
        |f(x) - f(y)| \leq A|x - y|^\sigma,
    \end{align*}
    where $A = \liminf_{k\to\infty}A_k$.
\end{enumerate}
\end{exercise}
\begin{proof}
~\begin{enumerate}[label=(\alph*)]
    \item First, since $\left\{A_k\right\}_{k\in \mathbb{N}}$ is bounded, then there exists $M > 0$ such that for all $k > 0, \left|A_k\right| < M$. For all $k > 0$ and all $x\in [-a,a]$, with $f_k(0) = 0$, we have
    \begin{align*}
        \left|f_k(x)\right| = \left|f_k(x) - f_k(0)\right| \leq A_k |x|^\sigma \leq a^\sigma M.
    \end{align*}
    Then, $\left\{f_k\right\}_{k\in \mathbb{N}}$ is bounded.
    
    Second, we want to prove that $\left\{f_k\right\}_{k\in \mathbb{N}}$ is equicontinuous. For $\forall \varepsilon > 0$, there exists $\delta = \left(\frac{\varepsilon}{M}\right)^{\frac{1}{\sigma}}$, then for $\forall f_k, \forall x, y \in [-a,a]$, if $|x - y| \leq \delta$, then 
    \begin{align*}
        \left|f_k(x) - f_k(y)\right| \leq A_k |x - y|^\sigma \leq M \frac{\varepsilon}{M} = \varepsilon.
    \end{align*}
    Then the set of all $f_k$ is compact. By Arzela-Ascoli theorem, there exists subsequence of $f_k$ converges uniformly to $f$ on $[-a,a]$.
    
    \item 
    \begin{enumerate}[label = \arabic*)]
        \item We use diagonal method to prove that there exists a subsequence $\left\{f_{k_i}\right\}^\infty_{i=1}$ of $\left\{f_k\right\}_{k\in \mathbb{N}}$ converging pointwise to $f$ on $\mathbb{R}$. For interval $[-1,1]$, $\left\{f_k\right\}_{k\in \mathbb{N}}$ has a convergent subsequence, denoted by $f_{11}, f_{12}, \cdots$. Now the sequence $\left\{f_{1n}\right\}$ is bounded on the interval $[-2,2]$, thus it has convergent subsequence, denoted by $f_{21}, f_{22}, \cdots$. Continue this process and we have subsequences
        \begin{align*}
            & f_{11}, f_{12}, f_{13}, \cdots \\
            & f_{21}, f_{22}, f_{23}, \cdots \\
            & f_{31}, f_{32}, f_{33}, \cdots \\
            & \cdots 
        \end{align*}
        and sequence in each line is a subsequence of the previous one. Now we select $f_{11}, f_{22}, f_{33}, \cdots$. 
    
        Now we claim $\{f_{nn}\}$ is pointwise convergent at every point in $\mathbb{R}$. First, $\{f_{nn}(x), x \in [-i, i]\}$ is convergent for for every $i = 1,2,\cdots$. Indeed, the sequence 
        $$f_{11}(x), f_{22}(x), f_{33}(x), \cdots$$
        is a subsequence of the convergent sequence $f_{i1}(x), f_{i2}(x), f_{i3}(x), \cdots$. Second, let $\varepsilon > 0$, take $\delta > 0$ as before. Then, for $\forall x \in \mathbb{R}$, and $|x - y| < \delta$, there exists $N_1 > 0$ such that $x, y\in [-N_1,N_2] \subset [-a,a]$. Since the sequence $f_{nn}(y)$ is convergent, then there is $N_2 > 0$ such that for all $n,m \geq N_2$, 
        \begin{align*}
            \left|f_{nn}(y) - f_{mm}(y)\right| \leq \varepsilon.
        \end{align*}
        Now, for $N = \max\{N_1, N_2\}$, and $\forall n, m > N$, if $|x - y| < \delta$, then 
        \begin{align*}
            \left|f_{nn}(x) - f_{mm}(x)\right| & \leq \left|f_{nn}(x) - f_{nn}(y)\right| + \left|f_{nn}(y) - f_{mm}(y)\right| + \left|f_{nn}(y) - f_{mm}(x)\right| \leq 3 \varepsilon.
        \end{align*}
        Hence, $\{f_{nn}(x)\}$ is convergent as a Cauchy sequence. Set $f(x) = \lim_{m\to\infty}f_{mm}(x)$, then for $x\in \mathbb{R}$, there exists $N > 0$ such that for all $n > N$, 
        \begin{align*}
            \left|f_{nn}(x) - f(x)\right| \leq 3\varepsilon.
        \end{align*}
        Thus, $\{f_{nn}(x)\}$ is pointwise convergent to $f(x)$ on $\mathbb{R}$.
        
        \item Now we have a subsequence $\{f_{k_i}\}$ of $\{f_k\}$ such that for any $x \in \mathbb{R}$, $\lim_{i\to \infty}f_{k_i}(x) = f(x)$. Then, 
        \begin{align*}
            \left|f(x) - f(y)\right| = \lim_{i\to\infty} \left|f_{k_i}(x) - f_{k_i}(y)\right|.
        \end{align*}
        Also, we know a proposition about $\liminf$ \footnote{This proposition states that let $\{x_n\}$ be a bounbed sequence in $\mathbb{R}$ and $a\in \mathbb{R}$, if $a > \liminf x_n$, then there exists $k \in \mathbb{N}$ such that for all $n \geq k$, $x_n > a$.} that if $H > \liminf_{k\to\infty} A_k$, then there exists $N > 0$, for all $k > N$, such that $A_k < H$\cite{1}. Then we take $H = \liminf_{k\to\infty}A_k + \varepsilon$ and let $\varepsilon \to 0$, then we have $\lim_{i\to\infty} \left|f_{k_i}(x) - f_{k_i}(y)\right| \leq \liminf_{k\to\infty}A_k |x - y|^\sigma$.
    \end{enumerate}
\end{enumerate}
\end{proof}

\medskip


\begin{exercise}{\rm *}
Prove that if $X$ is a metric space and $f:X \times [0,1] \to \mathbb{R}$ is a continuous function, then $g:X \to \mathbb{R}$, defined by $g(x) = \sup_{t\in [0,1]}f(x,t)$ is also continuous. 
\end{exercise}
\begin{proof}
Prove by contradiction and suppose $g$ is not continuous. Then there exists $\varepsilon > 0$, for all $\delta > 0$, there exists $x_0 \in X$ such that if $d_X(x,x_0) < \delta$, then $|g(x) - g(x_0)| > \varepsilon$. 

Fix such $\varepsilon$ and pick $\delta = 1/n$, then there exists $x_n \in X$ such that if $d_X(x_n, x_0) < \delta$, then $|g(x_n, x_0)| > \varepsilon$, i.e., 
\begin{align*}
    \left|\sup_{t}f(x_n,t) - \sup_{t}f(x_0,t)\right| > \varepsilon.
\end{align*}
Also, there exists $t_n, t_0 \in [0,1]$ such that $f(x_n, t_n) = \sup_{t}f(x_n,t)$ and $f(x_n, t_0) = \sup_{t}f(x_0,t)$. Then, we have 
\begin{align*}
    \left|f(x_n,t_n) - f(x_0,t_0)\right| > \varepsilon,
\end{align*}
where $x_n \to x_0$. Since $\{t_n\}$ is bounded in compact set $[0,1]$, then it has a convergent subsequence $\{t_{n_k}\}$ such that $t_{n_k}\to s$ and $f(x_{n_k}, t_{n_k}) \to f(x_n, s)$ since $f$ is continuous. Then, 
\begin{align*}
    f\left(x_{n_k}, t_{n_k}\right) & = \sup_{t} f\left(x_{n_k}, t\right) \geq f\left(x_{n_k}, t_0\right), \\
    f\left(x_n, t_0\right) & = \sup_{t}f(x_n,t) \geq f(x_n, s),
\end{align*}
which yields
\begin{align*}
    f\left(x_n, t_0\right) \gets f\left(x_{n_k}, t_0\right) \leq f\left(x_{n_k}, t_{n_k}\right) \to f\left(x_n, s\right) \leq f\left(x_n, t_0\right).
\end{align*}
Thus, $f\left(x_{n_k}, t_{n_k}\right) \to f\left(x_n, t_0\right)$, which is a contradiction.
\end{proof}

\medskip

\begin{exercise}\label{May_2019_3}
Prove that there is no continuous and one-to-one function $f:\mathbb{R}^2 \to \mathbb{R}$. \textbf{Hint:} \textit{Assume that such a function exists and then restrict the function to the unit circle in $\mathbb{R}^2$}.
\end{exercise}
\begin{proof}
Let $S^1 = \{(x,y)| x^2 + y^2 = 1\}$. Suppose there exists continuous and one-to-one function $f: S^1 \to \mathbb{R}$. Now let $g(x) = f(x) - f(-x)$, then $g$ is also continuous. And,
\begin{align*}
    g(-x) = f(-x) - f(x) = - g(x),
\end{align*}
then $g$ is an odd function. If $g(x) = 0$, then $f(x) = -f(x)$. If not, then $g(x) > 0$ and $g(-x) < 0$ of $g(x) < 0$ and $g(-x) > 0$. In either case, $S^1$ is a connected subspace of $\mathbb{R}^2$, with intermediate value theorem, there exists $c$ between $x$ and $-x$ such that $g(c) = 0$. Thus, $f(c) = f(-c)$. Thus, $f$ cannot be one-to-one, which is a contradiction\cite{2}.
\end{proof}

\medskip

\begin{proof}[Second Proof of Exercise \ref{May_2019_3}]
Since $S^1$ is compact, then $f$ attains maximum $a$ at some point $x_a \in S^1$ and minimum $b < a$ at some point $x_b \in S^1$. These two points separate the circle into two arcs. On each of the two arcs, the function $f$ will attain $\frac{a+b}{2}$ at some points, denoted by $x_1$ and $x_2$, since $f$ is continuous. Then $f(x_1) = f(x_2)$, which is contradicted by the fact that $f$ is one-to-one\cite{3}.
\end{proof}

\medskip

\begin{exercise}\label{May_2019_4}
Suppose $f: \mathbb{R}^2_+ \to \mathbb{R}$ is a continuous function defined on
\begin{align*}
    \mathbb{R}^2_+ = \{(x,y): x \in \mathbb{R}, y > 0\}.
\end{align*}
Assume also that the limits
\begin{align*}
    g(u,v) & = \lim_{t \to 0} \frac{f((u+t)\cos v, (u+t)\sin v) - f(u\cos v, u\sin v)}{t}, \\
    h(u,v) & = \lim_{t \to 0} \frac{f(u\cos (v+t), u\sin (v+t)) - f(u\cos v, u\sin v)}{t},
\end{align*}
exist and define continuous functions $g, h$ on the domain $D = \{(u,v): u > 0, 0 < v < \pi\}$. Prove that the function $f$ is differentiable on $\mathbb{R}^2_+$.
\end{exercise}
\begin{proof}
Define $M(u,v) = f(u\cos v, v\sin v) = f(x,y)$, where $u > 0, 0 < v < \pi$. And by assumption, $\frac{\partial M}{\partial u}$ and $\frac{\partial M}{\partial v}$ exist and are continuous. Then, for any $(u_1, v_1), (u_2, v_2) \in D$, there exist $\xi \in (u_1, u_2)$ and $\zeta \in (v_1,v_2)$ such that
\begin{align*}
    M(u_2,v_2) - M(u_1,v_1) & = M(u_2,v_2) - M(u_1,v_2) + M(u_1,v_2) - M(u_1,v_1) \\
    & = \frac{\partial M}{\partial u}(\xi, v_2)(u_2 - u_1) + \frac{\partial M}{\partial v}(u_1, \zeta)(v_2 - v_1).
\end{align*}
Then,
\begin{align*}
    & \lim_{(u_2,v_2) \to (u_1,v_1)}  \frac{\left|M(u_2,v_2) - M(u_1,v_1) - \frac{\partial M}{\partial u}(u_1, v_1)(u_2 - u_1) - \frac{\partial M}{\partial v}(u_1, v_1)(v_2 - v_1) \right|}{\left\|(u_2,v_2) - (u_1,v_1)\right\|} \\
    \leq & \underbrace{\left(\left|\frac{\partial M}{\partial u}(\xi, v_2) - \frac{\partial M}{\partial u}(u_1, v_1)\right| + \left|\frac{\partial M}{\partial v}(u_1, \zeta) - \frac{\partial M}{\partial u}(u_1, v_1)\right| \right)}_{\to 0} \underbrace{\frac{|u_2 - u_1|}{\left\|(u_2,v_2) - (u_1,v_1)\right\|}}_{\leq 1} \to 0.
\end{align*}
Thus, $M(u,v)$ is differentiable in $D$. So is $f$ on $\mathbb{R}^2_+$.
\end{proof}

\medskip

\begin{proof}[Second Proof of Problem \ref{May_2019_4}]
For any $(x_1, y_1), (x_2, y_2) \in \mathbb{R}^2_+$, there exist $(u_1, v_1), (u_2, v_2) \in D$ such that $(x_1, y_1) = (u_1 \cos v_1, u_1 \sin v_1)$ and $(x_2, y_2) = (u_2 \cos v_2, u_2 \sin v_2)$. Then,
\begin{align*}
    & \lim_{(x_2,y_2) \to (x_1,y_1)} \frac{\left|f(x_2,y_2) - f(x_1,y_1) - g(u_1,v_1)(u_2 - u_1) - h(u_1,v_1)(v_2 - v_1) \right|}{\sqrt{(x_2-x_1)^2 + (y_2-y_1)^2}} \\
    = & \lim_{(x_2,y_2) \to (x_1,y_1)} | f(u_2 \cos v_2, u_2 \sin v_2) - f(u_1 \cos v_2, u_2 \sin v_2) + f(u_1 \cos v_2, u_2 \sin v_2) \\
    & - f(u_1 \cos v_1, u_1 \sin v_1) - g(u_1,v_1)(u_2 - u_1) - h(u_1,v_1)(v_2 - v_1)| / \|x_2-x_1, y_2-y_1\| \\
    = &\,\,  0,
\end{align*}
where in the last step we used the definition of $g(u,v)$ and $h(u,v)$. Thus, $f$ is differentiable in $\mathbb{R}^2_+$.
\end{proof}

\medskip

\begin{proof}[Third Proof of Problem \ref{May_2019_4}]
Let $\Phi: D \to \mathbb{R}^2_+$ defined as $\Phi(u,v) = (u \cos v, u \sin v)$ is diffeomorphism, since $D\Phi(u,v) = \begin{bmatrix} \cos v & -u \sin v \\ \sin v & u \cos v \end{bmatrix} = u > 0$. Also,
\begin{align*}
    g(u,v) = \frac{\partial (f \circ \Phi)}{\partial u}, \quad h(u,v) = \frac{\partial (f \circ \Phi)}{\partial v}
\end{align*}
and partial derivatives of $f \circ \Phi$ are continuous, and then $f \circ \Phi \in C^1$. Thus, $f = (f \circ \Phi) \circ \Phi^{-1} \in C^1$.
\end{proof}

\medskip

\begin{exercise}
Let $f \in C^2(\Omega) \cap C^0(\overline{\Omega})$, where $\Omega \subset \mathbb{R}^n$ is open and bounded.
Let $\Delta f = \sum_{i=1}^n \partial^2f/\partial x_i^2$ be the Laplace operator.
\begin{enumerate}
    \item[(a)] Show that if for some $\varepsilon > 0$ and $x_0 \in \Omega$ we have $\Delta f(x_0) \geq \varepsilon$, then $f$ has no local maximum at $x_0$.
    
    \item[(b)] Conclude that if $\Delta f(x) \geq \varepsilon$ for some $\varepsilon > 0$ and all $x \in \Omega$, then we have $\sup_{\Omega} f = \sup_{\partial \Omega} f$.
    
    \item[(c)] Conclude that if $\Delta f(x) \geq 0$ for all $x \in \Omega$, then we have $\sup_{\Omega} f = \sup_{\partial \Omega} f$.
\end{enumerate}
{\bf Hint for part (c):} Observe that $\Delta |x|^2 = 2n$. Use it to modify a function $f$ in (c) so that you can apply part (b).
\end{exercise}
\begin{proof}
~\begin{enumerate}
    \item[(a)] Local maximum requires that $H_{x_0}(f)$ is positive semidefinitely, which means the trace $\partial^2f/\partial x_i^2, i = 1,2,\cdots,n$ of $H_{x_0}(f)$ are not positive. This is a contradiction with the fact $\Delta f(x_0) \geq \varepsilon$, then $f$ has no local maximum at $x_0$.
    
    \item[(b)] With (a), we can know that $f$ has no local maximum in $\Omega \setminus \partial \Omega$. Thus, $\sup_{\Omega} f = \sup_{\partial \Omega} f$.
    
    \item[(c)] Let $f_\varepsilon(x) = f(x) + \varepsilon |x|^2$, then $\Delta f_\varepsilon(x) = \Delta f(x) + 2 \varepsilon n$. Then, we have
    \begin{align*}
        \sup_{\Omega} f(x) \leq \sup_{\Omega} f_\varepsilon(x) \leq \sup_{\partial\Omega} f_\varepsilon(x) \leq \sup_{\partial \Omega} f(x) + 2 \varepsilon n \xrightarrow{\varepsilon \to 0} \sup_{\partial \Omega} f(x).
    \end{align*}
\end{enumerate}
\end{proof}

\medskip

\begin{exercise}
For $x = (x_1, x_2) \in \mathbb{R}^2$, let $|x| = \sqrt{x_1^2 + x_2^2}$. Let $D = \{x \in \mathbb{R}^2: |x| < 1\}$ and let $f: \overline{D} \to \mathbb{R}$ be continuous on $\overline{D}$. Prove that
\begin{align*}
    \lim_{n\to\infty} \int\int_D (n + 2)|x|^n f(x)\, dA = \int^{2\pi}_0 f(\cos t, \sin t)\, dt.
\end{align*}
\end{exercise}
\begin{proof}
Since $\overline{D}$ is compact, then $f$ attains maximum on $\overline{D}$, then there exists $M$ such that $|f(x)| \leq M, \forall x \in \overline{D}$. With polar coordinates, we want to prove that 
\begin{align*}
    \lim_{n\to\infty} \int^{2\pi}_0 \int^1_0 (n+2) |r|^{n+1} \left[f(r\cos t,r\sin t) - f(\cos t, \sin t) \right] \, dr dt = 0.
\end{align*}
Indeed, for any $\varepsilon > 0$, choose $a < 1$ such that $|f(r\cos t,r\sin t) - f(\cos t, \sin t)| < \varepsilon$ for $a < r < 1$, then 
\begin{align*}
    & \left| \int^{2\pi}_0 \int^1_0 (n+2) |r|^{n+1} \left[f(r\cos t,r\sin t) - f(\cos t, \sin t) \right] \, dr dt \right| \\
    \leq & \left| \int^{2\pi}_0 \int^a_0 (n+2) |r|^{n+1} \left[f(r\cos t,r\sin t) - f(\cos t, \sin t) \right] \, dr dt \right| \\
    & + \left| \int^{2\pi}_0 \int^1_a (n+2) |r|^{n+1} \left[f(r\cos t,r\sin t) - f(\cos t, \sin t) \right] \, dr dt \right| \\
    \leq & \underbrace{\int^{2\pi}_0 2 M a^{n+2} \, dt}_{\to 0\,\,{\rm as}\,\, n \to \infty}  + \underbrace{\int^{2\pi}_0 (n+2) \varepsilon \, dt}_{\to 0\,\,{\rm as}\,\, \varepsilon \to 0} \to 0.
\end{align*}
Thus, we complete the proof\footnote{This method comes from homework for Math1530 Advanced Calculus I: Let $f:[0,1] \to \mathbb{R}$ be continuous function. Prove that $\lim_{n\to\infty} n \int^1_0 x^n f(x)\, dx = f(1)$.}.
\end{proof}

\newpage

\section{August 2018 Exam}


\begin{exercise}
For $n$ a positive integer, put:
\begin{align*}
    t_n = \frac{1}{2n + 1} - \frac{1}{2n + 2} + \frac{1}{2n + 3} - \frac{1}{2n + 4} + \cdots + \frac{1}{4n - 1} - \frac{1}{4n},
\end{align*}
with $2n$ terms in the right hand side. Find, with proof, the following limit $\mathcal{T}$:
\begin{align*}
    \mathcal{T} = \lim_{n\to\infty} nt_n.
\end{align*}
{\bf Hint:} {\em Relate the given limit to suitable Riemann sums for the function $(1 + x)^{-1}$.}
\end{exercise}
\begin{proof}
\begin{align*}
    \mathcal{T} & = n \left(\frac{1}{2n + 1} + \frac{1}{2n + 3} + \cdots + \frac{1}{4n - 1}\right) - n \left(\frac{1}{2n + 2} + \frac{1}{2n + 4} + \cdots +  \frac{1}{4n}\right) \\
    & = n \int^2_0 \frac{1}{2 + x}\, dx - 2n \int^1_0 \frac{1}{1 + x}\, dx \\
    & = n\ln 4 - n\ln 2 - n\ln 2 \\
    & = 0.
\end{align*}
\end{proof}

\medskip

\begin{exercise}{\rm \cite{4}*}
Prove that if $f: [a,b] \to \mathbb{R}$ is continuous, the 
\begin{align*}
    \lim_{n\to\infty} \sqrt[n]{\int^b_a |f(x)|^n\, dx} = \sup_{x\in[a,b]} |f(x)|.
\end{align*}
\end{exercise}
\begin{proof}
~\begin{enumerate}[label=(\alph*)]
    \item Since $f$ is continuous on compact space $[a,b]$, then $f$ attains its maximum at some point $c \in [a,b]$ such that $|f(c)| = \sup_{x\in[a,b]} |f(x)| = M$. Then\footnote{We cannot use $\lim$ here since we could use it unless the limit exists. However, we do not know the limit exists. Thus, we use $\liminf$ and $\limsup$.},
    \begin{align*}
        \limsup_{n\to\infty} \sqrt[n]{\int^b_a |f(x)|^n\, dx} & \leq \limsup_{n\to\infty} M (b - a)^{\frac{1}{n}} = \sup_{x\in[a,b]} |f(x)|.
    \end{align*}
    
    \item Given $\varepsilon > 0$, it follows from the continuity of $|f|$ that $|f(x)| \geq M - \varepsilon$ for all $x \in [a,b]$ in some interval $I$ that contains $c$. Then,
    \begin{align*}
        \liminf_{n\to\infty} \sqrt[n]{\int^b_a |f(x)|^n\, dx} & \geq  \liminf_{n\to\infty} \sqrt[n]{\int_I |f(x)|^n\, dx} \geq \liminf_{n\to\infty} (M - \varepsilon) |I|^{\frac{1}{n}} = M - \varepsilon.
    \end{align*}
    Since the above inequality holds for any $\varepsilon > 0$, then taking $\varepsilon \to 0$ gives
    \begin{align*}
        M \leq \liminf_{n\to\infty} \sqrt[n]{\int^b_a |f(x)|^n\, dx} \leq \limsup_{n\to\infty} \sqrt[n]{\int^b_a |f(x)|^n\, dx} \leq M.
    \end{align*}
    Thus, the equality holds.
\end{enumerate}
\end{proof}

\medskip

\begin{exercise}
Let $\mathcal{M}$ denote the space of all real $2 \times 2$ matrices, equipped with the norm $\|A\| = \sqrt{{\rm tr} \left(A^T A\right)}$, for $A \in \mathcal{M}$. Consider the map $F$ from $\mathbb{R}^2$ to $\mathcal{M}$ given by formula, for any $(s,t) \in \mathbb{R}^2$:
\begin{align*}
    F(s,t) = \frac{1}{2} 
    \begin{vmatrix}
        \cos t + \cos s & \sin t + \sin s \\
        - \sin t + \sin s & \cos t - \cos s
    \end{vmatrix}.
\end{align*}
Denote by $\mathcal{N} \subset \mathcal{M}$ the space of all real $2 \times 2$ matrices of rank one and norm one. Prove that the image of $F$ is the space $\mathcal{N}$ and that the map $F$ is a local homeomorphism to its image. 
\end{exercise}
\begin{proof}
~\begin{enumerate}[label=(\alph*)]
    \item \begin{enumerate}[label=\arabic*)]
        \item Firstly, consider the elementary row operation of $F(s,t)$, which is
        \begin{align*}
            F(s,t) \to \frac{1}{2} 
            \begin{vmatrix}
                \cos t + \cos s & \sin t + \sin s \\
                0 & (\cos t - \cos s) + \frac{\sin^2 t - \sin^2 s}{\cos t + \cos s}
            \end{vmatrix} \to 
            \frac{1}{2}\begin{vmatrix}
                \cos t + \cos s & \sin t + \sin s \\
                0 & 0
            \end{vmatrix}.
        \end{align*}
        Also, $F(s,t)$ has rank one. Also, we have 
        $$\sqrt{{\rm tr} \left(F^T F\right)} = \sqrt{1/2 (\cos^2 t + \sin^2 t + \cos^2 s + \sin^2 s)} = 1.$$ 
        Thus, $F$ maps $\mathbb{R}^2$ to $\mathcal{N}$.
        
        \item Now we need to prove that $F$ is onto $\mathcal{N}$. For any matrix $A \in \mathcal{N}$, since $\rank A = 1$, we can assume 
        \begin{align*}
            A = \begin{vmatrix}
            a & b \\
            ka & kb
            \end{vmatrix},
        \end{align*}
        and then with norm being one, we have $(k^2 + 1)(a^2 + b^2) = 1$. 
        
        Now take\cite{5}
        \begin{align*}
            a & = \frac{\cos t + \cos s }{2} = \cos\left(\frac{t+s}{2}\right) \cos \left(\frac{t-s}{2}\right), \\
            b & = \frac{\sin t + \sin s }{2} = - \cos \left(\frac{t+s}{2}\right) \sin \left(\frac{t-s}{2}\right),
        \end{align*}
        and plug it back into $(k^2 + 1)(a^2 + b^2) = 1$ gives $k^2 = \sin^2 \left(\frac{t-s}{2}\right)/\cos^2 \left(\frac{t-s}{2}\right)$. Choosing $k = - \sin \left( \frac{t-s}{2} \right)/\cos \left( \frac{t-s}{2} \right)$ implies that $A$ can be represent by $F(s,t)$. Thus, $F$ is onto. Hence, the image of $F$ is the space $\mathcal{N}$.
    \end{enumerate}
    
    \item* The space $\mathcal{N}$ can be characterised as
    \begin{align*}
        \mathcal{N} = \left\{ \begin{pmatrix}
            a & b \\ 
            c & d
        \end{pmatrix}: a^2 + b^2 + c^2 + d^2=1, ad-bc = 0\right\}.
    \end{align*}
    The map $F$ can be viewed from $(s,t)$ to $\begin{pmatrix}
        x(s,t) & y(s,t) \\ 
        z(s,t) & w(s,t)
    \end{pmatrix}$, and the map $\begin{pmatrix}
        x & y\\ 
        z & w
    \end{pmatrix} \to \begin{pmatrix}
        a & b \\ 
        c & d
    \end{pmatrix}$ is a linear transformation and hence a homeomorphism\cite{6}.
\end{enumerate}
\end{proof}

\medskip

\begin{exercise}{\rm *}
Let $\mathcal{F} \subset C^\infty[0,1]$ be a uniformly bounded and equicontinuous family of smooth functions on $[0,1]$ such that $f' \in \mathcal{F}$ whenever $f \in \mathcal{F}$. Suppose that 
\begin{align*}
    \sup_{x\in[0,1]} \left|f'(x) - g'(x)\right| \leq \frac{1}{2} \sup_{x\in[0,1]} \left|f(x) - g(x)\right|, \,\, {\rm for all}\,\, f, g \in \mathcal{F}.
\end{align*}
Show that there exists a sequence $f_n$ of functions in $\mathcal{F}$ that converges uniformly to $Ce^x$ for some real value $C$.\\
{\bf Hint:} Use the contraction principle. In order to apply the the contraction principle you can use, without proof, the fact that if $X$ is a complete metric space, $A \subset X$ and $T: A \to X$ is uniformly continuous, then $T$ uniformly converges to a continuous map $\overline{T}: \overline{A} \to X$ defined on the closure $\overline{A}$.
\end{exercise}
\begin{proof}
$\mathcal{F}$ is a subset of the complete metric space $\left(C([0,1]), d_\infty \right)$. Let $\overline{\mathcal{F}}$ be the closure in that space, clearly, $\left(\overline{\mathcal{F}}, d_\infty \right)$ is a complete metric space as a closed subset of a metric space\footnote{If $X$ is a complete metric space, then a subset of $X$ is closed if and only if it is complete.\cite{7}} \footnote{{\bf Theorem:} Let $A \subset X$ be a closed subspace of a complete metric space $(X, d)$, then
$(A, d)$ is a complete metric space as well.\cite{8}}. The mapping $T: \mathcal{F} \to \mathcal{F} \subset \overline{\mathcal{F}}, Tf = f'$ satisfies
\begin{align*}
    d_\infty(Tf, Tg) \leq \frac{1}{2} d_\infty(f, g), \,\, \forall f,g \in \mathcal{F}.
\end{align*}
That means $T: \mathcal{F} \to \overline{\mathcal{F}}$ is Lipschitz continuous and hence uniformly continuous\cite{9}. Extend $T$ uniquely to a continuous mapping $\overline{T}: \overline{\mathcal{F}} \to \overline{\mathcal{F}}$ \footnote{Let $\left(X, d_X\right)$ be a metric space, $A \subset X$ is a dense subset and $\left(Y, d_Y\right)$ a complete metric space. If $f: A \to Y$ is uniformly continuous, then there is a unique continuous function $F: X \to Y$ such that $F(x) = f(x)$ for all $x \in A$. Also, $F$ is uniformly continuous.} such that 
\begin{align*}
    \overline{T}f = Tf = f', \,\, f \in \mathcal{F}.
\end{align*}
Note that 
\begin{align*}
    d_\infty \left(\overline{T}f, \overline{T}g \right) \leq \frac{1}{2} d_\infty (f,g), \,\, f, g \in \overline{\mathcal{F}}.
\end{align*}
Indeed, if $f, g \in \overline{\mathcal{F}}$, then there exists $\mathcal{F} \ni f_n \rightrightarrows f$ and $\mathcal{F} \ni g_n \rightrightarrows g$. Then,
\begin{align*}
    d_\infty \left(\overline{T}f, \overline{T}g \right) = \lim_{n\to\infty} d_\infty \left(\overline{T}f_n, \overline{T}g_n \right) \leq \lim_{n\to\infty} \frac{1}{2} d_\infty \left(f_n, g_n\right) = \frac{1}{2} d_\infty (f,g).
\end{align*}
Thus, $\overline{T}: \overline{\mathcal{F}} \to \overline{\mathcal{F}}$ is a contraction. Since $\left(\overline{F}, d_\infty \right)$ is complete, then $\overline{T}$ has a unique fixed point $\overline{T} f = f$. However, we cannot claim that $\overline{T}f = f'$, since $\overline{T}$ is defined as an extension of $Tg = g'$ to the space $\overline{\mathcal{F}}$ of continuous functions. 

However, we can argue as follows. If $g \in \mathcal{F} \subset \overline{\mathcal{F}}$ is any function, with the contraction principle, the iterations $\mathcal{F} \ni g_n = g^{(n)} = T^n g = \overline{T}^n g \rightrightarrows f$ converge uniformly to the unique fixed point of $\overline{T}$. Note that 
\begin{align*}
    g_n' = g^{(n+1)} = g_{n+1} \rightrightarrows f.
\end{align*}
Since $g_n \rightrightarrows f$, then $g_n' \rightrightarrows f$, and thus $f$ is differentiable and $f = f'$. For the completeness, 
\begin{align*}
    f(x) - f(0) \leftarrow g_n(x) - g_n(0) = \int^x_0 g_n'(t)\, dt \to \int^x_0 f_n'(t)\, dt,
\end{align*}
and then $f(x) - f(0) = \int^x_0 f_n'(t)\, dt$. Thus, $f'(x) = f(x)$ for $x \in [0,1]$, and hence $f(x) = Ce^x$ for some $C \in \mathbb{R}$. Indeed, 
\begin{align*}
    \left(f e^{-x} \right)' = f' e^{-x} - f e^{-x} = 0,
\end{align*}
and then $f e^{-x} = C$ for some $C$. Now we proved that if $g \in \mathcal{F}$, then
\begin{align*}
    \mathcal{F} \ni g_n = g^{n} \rightrightarrows C e^x.
\end{align*}
\end{proof}

\medskip

\begin{exercise}{\rm *}
Let $f: \mathbb{R}^n \to \mathbb{R}^n$ be a mapping of class $C^1$. Prove that there is an open and dense set $\Omega \subset \mathbb{R}^n$ such that the function $R(x) = \rank Df(x)$ is locally constant on $\Omega$, i.e., it is constant in a neighborhood of every point $x \in \Omega$.
\end{exercise}
\begin{proof}
Let $\Omega$ be the set of points where $R(x) = \rank Df(x)$ attains a local maximum, that is
\begin{align*}
    \Omega = \left\{x \,|\, \exists \varepsilon_1 > 0, \forall y \in B^n(x, \varepsilon), \rank Df(y) \leq \rank Df(x) \right\}.
\end{align*}
\begin{enumerate}[label=(\alph*)]
    \item We claim that $\Omega$ is open and $\rank Df$ is locally constant in $\Omega$. Indeed, $\{\rank Df \geq k\}$ is open \footnote{If $\rank Df(x) \geq k$, then the determinant of a certain $k\times k$ minor of $Df(x)$ is nonzero. Then we can choose a point $y \in B(x, \varepsilon)$ such that $\rank Df(y) \geq k$, since $\det$ function is continuous.}, so if $x \in \Omega$ and $\rank Df(x) = k$, then $\rank Df(y) \geq k$ in $B(x, \varepsilon_2)$. But $\rank Df$ attains locally maximum at $x$, then $\rank Df(y) = k$ in $B^n(x, \varepsilon)$, where $\varepsilon = \min \{\varepsilon_1, \varepsilon_2\}$. In particular, $B^n(x, \varepsilon) \subset \Omega$. This proves that $\Omega$ is open in $\Omega$ and $\rank Df$ is locally constant in $\Omega$. 
    
    \item It remains to prove that $\Omega$ is dense, Let $B^n(x, \varepsilon) \subset \mathbb{R}^n$ be any ball. It suffices to show that $\Omega \cap B^n(x, \varepsilon) \neq \varnothing$. Since $\rank Df$ attains only finitely many values, then it attains a global maximum in $B^n(x, \varepsilon)$, which is a local maximum in $\mathbb{R}^n$, so $\Omega \cap B^n(x, \varepsilon) \neq \varnothing$.
\end{enumerate}
\end{proof}

\medskip

\begin{exercise}{\rm *}
Let $\Phi: \mathbb{R}^2 \to \Phi\left(\mathbb{R}^2\right) \subset \mathbb{R}^2$ be a diffeomorpism. Prove that
\begin{align*}
    \int_{B^2(0,1)} \left\|D\Phi \right\| = \int_{\Phi(B^2(0,1))} \left\|D\left(\Phi^{-1}\right) \right\|,
\end{align*}
where $\|A\| = \left(\sum^2_{i,j=1} a_{ij}^2\right)^{1/2}$ is the Hilbert-Schmidt norm of the matrix.\\
{\bf Hint:} Compare $\|A\|$ and $\left\|A^{-1}\right\|$ for a $2 \times 2$ matrix.
\end{exercise}
\begin{proof}
For $A = \begin{pmatrix} 
    a & b \\
    c & d
\end{pmatrix}$, we have $\|A\| = \left(a^2 + b^2 + c^2 + d^2\right)^{1/2}$, then $A^{-1} = \frac{1}{ad - bc}\begin{pmatrix} 
    d & -b \\
    -c & a
\end{pmatrix}$ and thus $\left\|A^{-1}\right\| = \frac{\left(a^2 + b^2 + c^2 + d^2\right)^{1/2}}{ad - bc}$. 

Now we consider $\Phi: \mathbb{R}^2 \to \Phi\left(\mathbb{R}^2\right) \subset \mathbb{R}^2$, and for $x \in \mathbb{R}^2$, there exists $y \in \mathbb{R}^2$, $\Phi(x) = y$. Then, with 
\begin{align*}
    \int_{B^2(0,1)} (f \circ \Phi)\left|J_\Phi\right| = \int_{\Phi\left(B^2(0,1)\right)} f,
\end{align*}
taking $f = \left\|D\left(\Phi^{-1}\right) \right\|$ gives
\begin{align*}
    \int_{\Phi\left(B^2(0,1)\right)} \left\|D\left(\Phi^{-1}\right) \right\| = \int_{B^2(0,1)} \left\|D\left(\Phi^{-1}\right) (\Phi(x)) \right\| \cdot \left|J_\Phi\right|.
\end{align*}

Then it suffices to show that
\begin{align*}
    \left\|D\left(\Phi^{-1}\right) (\Phi(x)) \right\| \cdot \left|J_\Phi(x)\right| = \left\|D\Phi(x) \right\|.
\end{align*}
Also, we have $\Phi^{-1} \circ \Phi = I$\footnote{Here $I$ means identity map, like $f(x) = x, x \in \mathbb{R}^n$. Hence, the derivative of $\Phi^{-1} \circ \Phi$ is identity.}, then $D\left(\Phi^{-1}\right)(\Phi(x)) D\Phi(x) = I$. Then,
\begin{align*}
    D\left(\Phi^{-1}\right)(\Phi(x)) = \left(D\Phi(x)\right)^{-1},
\end{align*}
and then multiplying both sides by $\left|J_\Phi\right|$ gives
\begin{align*}
    \left\|D\left(\Phi^{-1}\right) (\Phi(x)) \right\| \cdot \left|J_\Phi(x)\right| = \left\|\left(D\Phi(x)\right)^{-1} \right\| \left|J_\Phi(x)\right|.
\end{align*}

Then it remains to show that 
\begin{align*}
    \left\|\left(D\Phi(x)\right)^{-1} \right\| \left|J_\Phi(x)\right| = \left\|D\Phi(x) \right\|.
\end{align*}
With above results, we have $\left\|A^{-1}\right\| |\det A|= \|A\|$, and the above equality follows.
\end{proof}


\newpage

\section{May 2018 Exam}


\begin{exercise}
Prove that every real-valued function, continuous on the real interval $[0,1]$, is the uniform limit of continuous piecewise linear functions.
\end{exercise}
\begin{proof}
For any continuous function $f:[0,1] \to \mathbb{R}$, we can separate $[0,1]$ into $n$ pieces, with step length $1/n$. Denote by $[x_j, x_{j+1}], 1 \leq j \leq n$ the interval $\left[\frac{j-1}{n}, \frac{j}{n}\right]$. We define linear function $f_j: [x_j, x_{j+1}] \to \mathbb{R}$ by
\begin{align*}
    f_j(x) = f(x_j) + \frac{f(x_{j+1}) - f(x_j)}{1/n} x,
\end{align*}
and then we can define a continuous piecewise linear function
\begin{align*}
    \widetilde{f}(x) = \begin{cases}
        f_1(x), & x \in [x_1, x_2], \\
        \quad \vdots \\
        f_n(x), & x \in [x_n, x_{n+1}].
    \end{cases}
\end{align*}

It remains to show that $f(x)$ converges uniformly to $\widetilde{f}(x)$. For any $\varepsilon > 0$, then for $x_j$, there exists a $\delta_j > 0$, such that if $|x - x_j| < \delta_j$, then $|f(x) - f(x_j)| < \varepsilon$. Now we can pick $N > 0$ such that $1/N < \min_{j}\{\delta_j\}$, i.e., the step length is less than $\min_{j}\{\delta_j\}$. Then, for any $n > N$, and any $x \in [0,1]$, we can find a $j$ such that $x \in [x_j, x_{j+1}]$. Then,
\begin{align*}
    \left|\widetilde{f}(x) - f(x)\right| & = \left|f_j(x) - f(x)\right| \\
    & \leq \left|f_j(x) -  f_j(x_{j+1})\right| + \left|f_j(x_{j+1}) - f(x)\right| \\
    & \leq \left|f_j(x_j) -  f_j(x_{j+1})\right| + \left|f(x_{j+1}) - f(x)\right| \\
    & \leq 2 \varepsilon,
\end{align*}
where in the last step, we used the continuity of linear function $f_j(x)$ in the interval $[x_j, x_{j+1}]$. Thus, $f$ converges uniformly to a continuous piecewise linear function.
\end{proof}

\medskip

\begin{exercise}
~\begin{enumerate}[label=(\alph*)]
    \item State a theorem that says under what considitions we can differentiate a function series term by term, i.e., $f_n:(a,b) \to \mathbb{R}$,
    \begin{align*}
        \left(\sum^\infty_{n=1}f_n(x) \right)' = \sum^\infty_{n=1} f_n'(x).
    \end{align*}
    
    \item Prove that if $a > 1$ and $k \geq 1$, then
    \begin{align*}
        \sum^\infty_{n=2} \frac{(\log n)^k}{n^a} < \infty.
    \end{align*}
    
    \item Prove that the function
    \begin{align*}
        \zeta(x) = \sum^\infty_{n=1} \frac{1}{n^x}, x > 1,
    \end{align*}
    is infinitely differentiable in $(1, \infty)$.
\end{enumerate}
{\bf Hint:} You can use part (b) to prove (c), even if you do not know how to prove (b).
\end{exercise}
\begin{proof}
~\begin{enumerate}[label=(\alph*)]
    \item Suppose that $f_n:(a,b) \to \mathbb{R}$ has continuous derivatives on $(a,b)$ and \footnote{\begin{intheorem}{\rm \cite{10}}
    Suppose that $f_n:[a,b] \to \mathbb{R}$ has continuous derivatives on $[a,b]$ and further that
    \begin{enumerate}[label=(\alph*)]
        \item the series $\sum^\infty_{n=1} f_n(x)$ converges at some point $x_0 \in (a, b)$,
        
        \item the series of derivatives $\sum^\infty_{n=1} f_n'(x)$ converges uniformly on $[a,b]$.
    \end{enumerate}
    Then,
    \begin{enumerate}[label=(\alph*)]
        \item the series $\sum^\infty_{n=1} f_n(x)$ converges at every $x \in [a,b]$ and the sum $\sum^\infty_{n=1} f_n(x)$ is differentiable with $\left( \sum^\infty_{n=1} f_n(x) \right)' = \sum^\infty_{n=1} f_n'(x)$ for each $x \in [a,b]$,
        
        \item the convergence of $\sum^\infty_{n=1} f_n(x)$ is uniform on $[a,b]$.
    \end{enumerate}
    \end{intheorem}}
    \begin{enumerate}[label=\arabic*)]
        \item the series $\sum^\infty_{n=1} f_n(x)$ converges at some point $x_0 \in (a, b)$,
        
        \item the series of derivative $\sum^\infty_{n=1} f_n'(x)$ converges uniformly on $(a,b)$.
    \end{enumerate}
    Then the series $\sum^\infty_{n=1} f_n(x)$ converges at every $x \in (a,b)$ and
    \begin{align*}
        \left(\sum^\infty_{n=1}f_n(x) \right)' = \sum^\infty_{n=1} f_n'(x).
    \end{align*}
    
    \item Since $a > 1$, then let $a = 1 + 2b > 1$, where $b > 0$. Then,
    \begin{align*}
        \lim_{n\to\infty} \frac{\frac{(\log n)^k}{n^{1+2b}}}{\frac{1}{n^{1+b}}} = \lim_{n\to\infty} \frac{(\log n)^k}{n^b} = 0,
    \end{align*}
    and to see the last step, we could assume $f(x) = \frac{(\log x)^k}{x^b}$. Since 
    \begin{align*}
        f'(x) = x^{-b-1} (\log x)^{k-1} (k - b \log x),
    \end{align*}
    then letting $x \to \infty$ gives $f'(x) < 0$, which implies that $f(x)$ is decreasing and thus $\lim_{x} f(x) = 0$, which gives $\lim_{n\to\infty} \frac{(\log n)^k}{n^b} = 0$. Now, since $\sum \frac{1}{n^{1+b}}$ converges, so does $\sum \frac{(\log n)^k}{n^a}$.
    
    \item For $x > 1$, 
    \begin{align*}
        \sum^\infty_{n=1} \frac{1}{n^x} < 1 + \sum^\infty_{n=2} \frac{(\log n)^k}{n^x} < \infty,
    \end{align*}
    then $\sum \frac{1}{n^x}$ converges for $x \in (1, \infty)$. Also, since $\left(\frac{1}{n^x}\right)' = - n^{-x} \log n$, then considering in $k = 1$ and $a = x > 1$ part (b) gives
    \begin{align*}
        \sum^\infty_{n=1} \left|\frac{\log n}{n^x} \right| < \infty.
    \end{align*}
    Therefore, by part (a),
    \begin{align*}
        \left(\sum^\infty_{n=1} \frac{1}{n^x}\right)' = \sum^\infty_{n=1} \left(\frac{1}{n^x}\right)'.
    \end{align*}
    
    Now we can continue this process and have
    \begin{align*}
        \left(\sum^\infty_{n=1} \frac{1}{n^x}\right)^{(n)} = \sum^\infty_{n=1} \left(\frac{1}{n^x}\right)^{(n)},
    \end{align*}
    and since $\frac{1}{n^x}$ is infinitely differentiable, so does $\zeta(x)$.
\end{enumerate}
\end{proof}

\medskip

\begin{exercise}
Let $f: \mathbb{Q}^n \to \mathbb{R}$ be a function defined on the set $\mathbb{Q}^n \subset \mathbb{R}^n$ consisting of points whose coordinates are rational numbers. Prove that if $f$ satisfies the inequality $|f(x) - f(y)|^{2018} \leq 2018 |x - y|$ for all $x, y \in \mathbb{Q}^n$, then there is a unique continuous function $F: \mathbb{R}^n \to \mathbb{R}$ such that $F(x) = f(x)$ for all $x \in \mathbb{Q}^n$. Provide a direct proof without referring to any deep results \footnote{This problem is similar to the following one: Let $f:A\to X$ be a mapping between a dense subset $A \subset \mathbb{R}^n$ and a complete metric space $(X,d)$. Assume that $d(f(x),f(y))\leq |x-y|$ for all $x,y\in A$. Prove that there is a mapping $F:\mathbb{R}^n\to X$ such that $d(F(x),F(y))\leq |x-y|$ for all $x,y\in \mathbb{R}^n$ and $F(x)=f(x)$ whenever $x\in A$.}.
\end{exercise}
\begin{proof}
Since $\mathbb{Q}^n$ is dense in $\mathbb{R}^n$, then for any point $x$ in $\mathbb{R}^n$, we can find a sequence $\{x_n\}^\infty_{n=1}$ of points in $\mathbb{Q}^n$ such that $\lim_{n\to\infty} x_n = x$. Now we define $F(x)$ as
\begin{align*}
    F(x) = \begin{cases}
        \lim_{n\to\infty} f(x_n), & x \notin \mathbb{Q}^n,  x_n \in \mathbb{Q}^n, \lim_{n\to\infty} x_n = x, \\
        f(x), & x \in \mathbb{Q}^n.
    \end{cases}
\end{align*}
Then, it is natural that $F(x) = f(x)$ for all $x \in \mathbb{Q}^n$. 

It remains to show that $F(x)$ defined above is unique. Suppose that there exists another continuous function $G(x)$ such that $G(x) = f(x)$ for all $x \in \mathbb{Q}^n$, but $G(x) \neq F(x)$ for all $x \notin \mathbb{Q}^n$. However, for $x \notin \mathbb{Q}^n$,
\begin{align*}
    |F(x) - G(x)| \leq |F(x) - f(x_n)| + |f(x_n) - G(x)| \xrightarrow[]{n \to \infty} 0,
\end{align*}
where we used the fact that $G(x)$ is continuous. This is a contradiction.
\end{proof}

\medskip

\medskip

\begin{exercise}{\rm *}
Let $P = \{(x_1, x_2, x_3, x_4): x_4 = 0\}$ be a hyperplane in $\mathbb{R}^4$. Let $\Phi: \mathbb{R}^4 \to \mathbb{R}^4$ be a $C^1$-diffeomorphism of $\mathbb{R}^4$ onto $\mathbb{R}^4$, and let $S = \Phi(P)$ be the image of the hyperplane $P$ under the diffeomorphism $\Phi$. Prove that for every $x \in S$, there is a neighborhood $B(x, \varepsilon) \subset \mathbb{R}^4$ such that the set $S\cap B(x, \varepsilon)$ is a graph of a $C^1$ function of one of the following forms
\begin{align*}
    x_1 = f(x_2, x_3, x_4), \,\,\, {\rm or} \,\,\, x_2 = f(x_1, x_3, x_4), \,\,\, {\rm or} \,\,\, x_3 = f(x_1, x_2, x_4), \,\,\, {\rm or} \,\,\, x_4 = f(x_1, x_2, x_3).
\end{align*}
In the proof you are allowed to use the inverse function theorem or the implicit function function theorem only.
\end{exercise}
\begin{proof}
Define $\Psi = (\Psi_1, \Psi_2, \Psi_3, \Psi_4): \mathbb{R}^4 \to \mathbb{R}^4$ being inverse diffeomorphism such that $\Psi(S) = P$. Then,
\begin{align*}
    S & = \{(x_1, x_2, x_3, x_4): \Psi(x_1, x_2, x_3, x_4) \in P\} \\
    & = \{(x_1, x_2, x_3, x_4): \Psi_4(x_1, x_2, x_3, x_4) = 0\}. 
\end{align*}
Since $\Psi$ is a diffeomorphism, then $\det D\Psi \neq 0$ everywhere. And since 
\begin{align*}
    D\Psi = \begin{pmatrix} 
    \nabla \Psi_1 \\
    \nabla \Psi_2 \\
    \nabla \Psi_3 \\
    \nabla \Psi_4
    \end{pmatrix},
\end{align*}
then $\nabla \Psi_4 \neq 0$ everywhere and therefore, $\nabla \Psi_4 \neq 0$ on the surface $S$. Then we have
\begin{align*}
    \frac{\partial \Psi_4}{\partial x_i} \neq 0,
\end{align*}
for some $i = 1,2,3,4$. Thus, by implicit function theorem, for every $x \in S$, there is a neighborhood $B(x, \varepsilon)$ such that the set $S \cap B(x, \varepsilon)$ is a graph of a $C^1$ function of the form 
\begin{align*}
    x_i = f(x_1, \cdots, \hat{x}_i, \cdots, x_4),
\end{align*}
for some $i = 1,2,3,4$, where $\hat{x}_i$ indicates that $x_i$ is ignored.
\end{proof}

\medskip

\begin{exercise}{\rm *}
Let $n$ be a positive integer. Denote by $\mathcal{M}_n$ the space of all real $n \times n$ matrices. By $A^T \in \mathcal{M}_n$ denote the transpose of a matrix $A \in \mathcal{M}_n$ and by $tA, t \in \mathbb{R}$, the matrix where all components of $A$ are multiplied by $t$. Prove that if $A \in \mathcal{M}_n$, then there is $B \in \mathcal{M}_n$ and $\varepsilon > 0$ such that $\varepsilon A = B + B^T B$.\\
{\bf Hint:} Differentiate the mapping $F: \mathcal{M}_n \to \mathcal{M}_n$ defined by $F(X) = X + X^TX$.
\end{exercise}
\begin{proof}
Let $F(X) = X + X^TX$, and we need to find $DF(0)$. It suffices to find a map $L:\mathcal{M}_n \to \mathcal{M}_n$ such that
\begin{align*}
    \lim_{H \to 0} \frac{F(H) - F(0) - L(H)}{\|H\|} = 0.
\end{align*}
Taking $L(H) = H$ gives
\begin{align*}
    \lim_{H \to 0} \left\|\frac{H + H^TH - H}{H}\right\| = \lim_{H \to 0} \frac{\left\|H^TH \right\|}{\|H\|} \leq \lim_{H \to 0} \|H\| = 0.
\end{align*}
Then, $DF(0) = I$. By inverse function theorem, $F$ is a diffeomorphism near $0 \in \mathcal{M}_n$. Then, $F$ maps a neighorhoood $U \subset \mathcal{M}_n$, where $0 \in U$ onto a neighorhood $V \in \mathcal{M}_n$, that is also $0 \in V$. Then, for any $A \in \mathcal{M}_n$, there is a $\varepsilon > 0$ small enough such that $\varepsilon \|A\| < \delta$, where $\delta$ is the radius of a ball contained in $V$, that is, $B^{n^2}(0,\delta) \subset V$. Thus, $A \in V$ and there exists $B \in U$ such that $\varepsilon A = B + B^T B$.
\end{proof}

\medskip

\begin{exercise}
Let $f$ be a polynomial of total degree at most three in $(x, y, z) \in \mathbb{R}^3$.  Prove that:
$$
\int_{x^2 + y^2 + z^2 \le 1} f(x, y, z)\hspace{1.5pt} dx\hspace{1.5pt}  dy \hspace{1.5pt} dz =
\frac{4\pi f((0, 0, 0)) }{3} +  \frac{2\pi \left(\Delta f\right)((0, 0, 0))}{15}.
$$
Here $\displaystyle{\Delta = \frac{\partial^2}{\partial x^2} + \frac{\partial^2}{\partial y^2} + \frac{\partial^2}{\partial z^2}}$ is the Laplacian operator on $\mathbb{R}^3$.
\end{exercise}
\begin{proof}
By Taylor's formula, 
\begin{align*}
    f(x) = f(0) + \sum^3_{i=1} \frac{\partial f}{\partial x_i}(0) x_i + \frac{1}{2} \sum^3_{i,j=1} \frac{\partial^2 f}{\partial x_i \partial x_i}(0)x_i x_i + \frac{1}{6} \sum^3_{i,j,k=1} \frac{\partial^3 f}{\partial x_i \partial x_i \partial x_k}(0)x_i x_i x_k + R.
\end{align*}
and since $f$ is a polynomial of degree at most $3$, then the remainder $R = 0$. Also, with the property of odd function,
\begin{align*}
    \int_B x_i\, dx = 0,\quad \int_B x_i x_i x_k\, dx = 0,
\end{align*}
and
\begin{align*}
    \int_B x_i x_i\, dx = 0,\,\, i\neq j.
\end{align*}
Then, 
\begin{align*}
    \int_B f(x, y, z)\, dx\,dy\,dz = f(0) \underbrace{\int_B\, dx}_{4\pi/3}  + \frac{1}{2} \sum^3_{i=1} \frac{\partial^2 f}{\partial x^2_i}(0) \int_B x_i^2\, dx,
\end{align*}
also, with 
\begin{align*}
    \int_B x_1^2\, dx = \int_B x_2^2\, dx = \int_B x_3^2\, dx & = \frac{1}{3} \int_B |x|^2\, dx \\
    & = \int^1_0 \int_{S(r)} r^2\, d\sigma\, dr \\
    & = \int^1_0 r^2 \cdot 4\pi r^2\, dr = \frac{4\pi}{5},
\end{align*}
the proof is completed. 
\end{proof}







\newpage
\bibliographystyle{unsrt}
\bibliography{bibliography}


\end{document}